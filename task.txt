Задание (максимальное время выполнения 6-8 часов)

Реализовать CLI приложение-парсер сайта по заданному url со следующим функционалом:
1. Команда parse - запускает парсер, принимает обязательный параметр url (как с протоколом, так и без).
1.1. При переходе по переданному url, приложение должно найти все картинки, расположенные на странице, и сохранить их полные пути и страницу источник.
1.2. На анализируемой странице должны быть найдены все ссылки, ведущие на другие страницы данного домена, для каждой из этих страниц должен быть выполнен пункт 1.1. и 1.2.
1.3. В конце выполнения команда должна выдать ссылку на CSV файл с результатами анализа.
2. Команда report - выводит в консоль результаты анализа для домена, принимает обязательный параметр domain (как с протоколом, так и без).
3. Команда help - выводит список команд с пояснениями.

Дополнительные требования к заданию:
— архитектура должна быть легко расширяема.
Например: если нужно дополнительно сохранять все внешние ссылки или все заголовки на странице, должна быть возможность создать отдельный обработчик (реализовывать это не надо).

Обязательные требования:
— реализация на plain PHP;
— использование composer;
— OOP, SOLID, DRY;
— реализация должна быть размещена в публичном репозитории (bitbucket, github).

Запрещается:
— использовать фреймворки и их компоненты;
— использовать чужие библиотеки (даже Guzzle).

Разрешается:
— использовать свои библиотеки (при условии подключения их через composer);
— использовать любой удобный способ хранения данных.


DTO
register handler

Scraper
    WebPageScraper
        UrlScraper
        ImageScraper
DTO
ScrapingResultsDTO
    Url
    images[]
    ---
    getUrl()
    getImages()

type hinting
immutability

проверка на то что эта ссылка уже парсилась
замомнить
вернуть список ссылок

Вид csv
/home
    images:
            a.png
            p.png
/catalog:
    images:
            c.jpeg
            d.jpeg


ссылка;img1,img2,img3
ссылка;img1,img2,img3

ValueObject - Url



запретить изменение в DTO
Заменить Url на url
вывод или return
Разобратся со возвращаемыми типами
    webscrapper:   public function run(Url $url):ScrapedData
Заменить типы в докблоке на более конкретные.